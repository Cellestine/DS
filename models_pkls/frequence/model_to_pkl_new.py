import os
import joblib
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.preprocessing import StandardScaler
from xgboost import XGBRegressor

# ---------------------------------------------
# Chargement des fichiers
# ---------------------------------------------
X_train = pd.read_csv("train_input_Z61KlZo (1).csv", low_memory=False)
y_train = pd.read_csv("train_output_DzPxaPY (1).csv")["FREQ"]
X_test = pd.read_csv("test_input_5qJzHrr.csv", low_memory=False)

# ---------------------------------------------
# Colonnes (issues de config)
# ---------------------------------------------
NUMERICAL_COLUMNS = [
    "ID", "TYPERS", "ANCIENNETE", "DUREE_REQANEUF", "TYPBAT2",
    "KAPITAL12", "KAPITAL25", "KAPITAL32", "SURFACE1", "SURFACE4", "SURFACE10",
    "NBBAT1", "RISK1", "RISK7", "EQUIPEMENT4", "EQUIPEMENT6", "ZONE_VENT",
    "ANNEE_ASSURANCE", "ZONE",
    "surface_totale", "capital_total", "surface_par_batiment",
    "capital_par_surface", "capital_moyen_par_batiment"
]

CATEGORIAL_COLUMNS = [
    "ACTIVIT2", "VOCATION", "CARACT1", "CARACT3", "CARACT4",
    "TYPBAT1", "INDEM2", "FRCH1", "FRCH2", "DEROG12", "DEROG13", "DEROG14",
    "DEROG16", "TAILLE1", "TAILLE2", "COEFASS", "RISK6", "RISK8", "RISK9",
    "RISK10", "RISK11", "RISK12", "RISK13", "EQUIPEMENT2", "EQUIPEMENT5"
]

ALL_COLUMNS = NUMERICAL_COLUMNS + CATEGORIAL_COLUMNS

# Cr√©ation de variables d√©riv√©es
for df in [X_train, X_test]:
    df["surface_totale"] = df[["SURFACE1", "SURFACE4", "SURFACE10"]].apply(pd.to_numeric, errors="coerce").sum(axis=1)
    df["capital_total"] = df[["KAPITAL12", "KAPITAL25", "KAPITAL32"]].apply(pd.to_numeric, errors="coerce").sum(axis=1)
    df["surface_par_batiment"] = df["surface_totale"] / df["NBBAT1"].replace(0, np.nan)
    df["capital_par_surface"] = df["capital_total"] / df["surface_totale"].replace(0, np.nan)
    df["capital_moyen_par_batiment"] = df["capital_total"] / df["NBBAT1"].replace(0, np.nan)

# Forcer la conversion des colonnes num√©riques
for col in NUMERICAL_COLUMNS:
    if col in X_train.columns:
        X_train[col] = pd.to_numeric(X_train[col], errors="coerce")
    if col in X_test.columns:
        X_test[col] = pd.to_numeric(X_test[col], errors="coerce")

# ---------------------------------------------
# D√©finition des classes custom
# ---------------------------------------------
class ColumnSelector(BaseEstimator, TransformerMixin):
    def __init__(self, selected_columns):
        self.selected_columns = selected_columns

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        return X[self.selected_columns].copy()


class MissingValueFiller(BaseEstimator, TransformerMixin):
    def __init__(self, num_cols=None, cat_cols=None):
        self.num_cols = num_cols
        self.cat_cols = cat_cols

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X_copy = X.copy()
        if self.num_cols:
            for col in self.num_cols:
                if col in X_copy.columns:
                    X_copy[col] = X_copy[col].fillna(0)
        if self.cat_cols:
            for col in self.cat_cols:
                if col in X_copy.columns:
                    X_copy[col] = X_copy[col].fillna("Inconnu")
        return X_copy


class ManualCountEncoder(BaseEstimator, TransformerMixin):
    def __init__(self, cat_cols=None):
        self.cat_cols = cat_cols
        self.count_maps = {}

    def fit(self, X, y=None):
        for col in self.cat_cols:
            counts = X[col].value_counts()
            self.count_maps[col] = counts.to_dict()
        return self

    def transform(self, X):
        X_copy = X.copy()
        for col in self.cat_cols:
            if col in X_copy.columns:
                X_copy[col] = X_copy[col].map(self.count_maps.get(col, {})).fillna(0)
            else:
                X_copy[col] = 0
        return X_copy


class ColumnDropper(BaseEstimator, TransformerMixin):
    def __init__(self, num_cols=None, missing_thresh=0.4, var_thresh=0.01, corr_thresh=0.95):
        self.num_cols = num_cols
        self.missing_thresh = missing_thresh
        self.var_thresh = var_thresh
        self.corr_thresh = corr_thresh
        self.columns_to_drop_ = []

    def fit(self, X, y=None):
        X_copy = X.copy()
        drop_cols = []

        for col in X_copy.columns:
            if col in self.num_cols:
                missing_ratio = (X_copy[col] == 0).sum() / len(X_copy)
            else:
                missing_ratio = (X_copy[col] == "Inconnu").sum() / len(X_copy)
            if missing_ratio > self.missing_thresh:
                drop_cols.append(col)

        var_series = X_copy.var(numeric_only=True)
        low_var_cols = var_series[var_series < self.var_thresh].index.tolist()
        drop_cols += low_var_cols

        corr_matrix = X_copy.select_dtypes(include=["number"]).corr().abs()
        upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
        high_corr_cols = [col for col in upper_tri.columns if any(upper_tri[col] > self.corr_thresh)]
        drop_cols += high_corr_cols

        self.columns_to_drop_ = list(set(drop_cols))
        return self

    def transform(self, X):
        return X.drop(columns=self.columns_to_drop_, errors="ignore")


class ScalerWrapper(BaseEstimator, TransformerMixin):
    def __init__(self, num_cols=None):
        self.num_cols = num_cols
        self.scaler = StandardScaler()

    def fit(self, X, y=None):
        if self.num_cols:
            self.scaler.fit(X[self.num_cols])
        return self

    def transform(self, X):
        X_copy = X.copy()
        if self.num_cols:
            X_copy[self.num_cols] = self.scaler.transform(X_copy[self.num_cols])
        return X_copy

# ---------------------------------------------
# Cr√©ation pipeline complet
# ---------------------------------------------
preprocessing_pipeline = Pipeline([
    ("select", ColumnSelector(ALL_COLUMNS)),
    ("missing", MissingValueFiller(NUMERICAL_COLUMNS, CATEGORIAL_COLUMNS)),
    ("encoding", ManualCountEncoder(CATEGORIAL_COLUMNS)),
    ("drop", ColumnDropper(NUMERICAL_COLUMNS)),
    ("scaling", ScalerWrapper(NUMERICAL_COLUMNS))
])

X_train_processed = preprocessing_pipeline.fit_transform(X_train)
X_test_processed = preprocessing_pipeline.transform(X_test)

model = XGBRegressor(objective="count:poisson", random_state=42)
model.fit(X_train_processed, y_train)


# ---------------------------------------------
# Pipeline final avec mod√®le
# ---------------------------------------------
full_pipeline = Pipeline([
    ("preprocessing", preprocessing_pipeline),
    ("model", model)
])

# üîÅ Pr√©diction sur les 10 premi√®res lignes du test
print("‚úÖ Pr√©dictions effectu√©es avec succ√®s sur les 10 premi√®res lignes du test.")
for i, x in enumerate(X_test.iloc[:10].to_dict(orient="records"), 1):
    input_df = pd.DataFrame([x])
    prediction = full_pipeline.predict(input_df)[0]
    print(f"Pr√©diction {i}: {round(prediction, 2)}")


joblib.dump(full_pipeline, "new_full_model_pipeline.pkl")
print("‚úÖ Nouveau pipeline sauvegard√© sous new_full_model_pipeline.pkl")
